---
layout: post
title: Naive Bayes Classification Algorithm
subtitle: With Numpy
bigimg: /img/Bayes-Theorum.png
tags: [Algorithms, Bayes Theorum, Computer Science]

---
# Description
If you want to know about Naive Bayesian Classification Algorithms, you first need to know about what they are based on. In 
statistics, there is a family of classification algorithms that rely on the underlying probabilistic assumptions about the
distribution of features, datapoints and outcomes in a dataset. These algorithms and classifiers are based on applying Bayes' 
Theorum to a problem that can be classified by a defined state -- for example, A or B, or, 0 or 1.

Theorectically, Bayes' Theorum describes the probability of an event occuring, predicated on the prior knowledge related to 
that event and the subsequent outcome. For example, if it is known that a person has a particular gene associated with cancer, 
Bayes' Theorum can help assess the probabilistic risk of developing cancer by evaluating various criterion, including that 
specific genes prescence. This allows for more nuanced assessment of a particular combination of factors specific to that 
context. In application, when interpreting the probability, the theorum expresses how the probability of an event should be 
updated to reflect the changing evidence over time. This implies that as more information comes to light, the probability 
associated with a specific outcome will change according to the new information and the distribution of the factors that are 
being evaluated. For example, as medicine becomes more advanced, if a breakthrough comes out that allows for a change to made 
to a persons DNA, and they have a cancer-causing gene, the probability you develop cancer, if you have this procedure, will 
fall -- which in term can be accounted for with Bayes Theorum (more specifically a Naive Bayes Classification Algorithm).


# Use Case
Naive Bayes' Algorithms are so called because they make naive assumptions about the relationships between features,
datapoints and outcomes. One element that underlies all Naive Bayes Classifiers is that the assumed value associaed with a 
particular feature is independent of all others -- meaning that it does not consider the correlation between



# How - To






